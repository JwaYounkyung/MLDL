{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import PIL.Image as pilimg\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from models.densenet import densenet121\n",
    "from models.vgg import VGGNet\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C100Dataset:\n",
    "    \"\"\"\n",
    "    X is a feature vector\n",
    "    Y is the predictor variable\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        ## read the csv for dataset (cifar100.csv, cifar100_lt.csv or cifar100_nl.csv), \n",
    "        # \n",
    "        # Format:\n",
    "        #   image file path,classname\n",
    "        \n",
    "        ### TODO: Read the csv file and make the training and testing set\n",
    "        ## YOUR CODE HERE\n",
    "        self.filename=filename\n",
    "        f=open(filename)\n",
    "        rdr=csv.reader(f)\n",
    "        path=[]\n",
    "        label=[]\n",
    "        \n",
    "        for line in rdr:\n",
    "            rpath=line[0].replace('cifar100','../dataset')\n",
    "            path.append(rpath)\n",
    "            label.append(line[1])\n",
    "        f.close()\n",
    "\n",
    "        self.tr_x = []\n",
    "        self.tr_y = []\n",
    "        self.ts_x = []\n",
    "        self.ts_y = []\n",
    "\n",
    "\n",
    "        for i in range(len(label)):\n",
    "            img = pilimg.open(path[i])#path 읽어와서 이미지 열기\n",
    "            pixel = np.array(img)\n",
    "            pixel = np.transpose(pixel, (2, 1, 0))\n",
    "            cat=path[i].split('/')\n",
    "            if cat[3]=='train':\n",
    "                self.tr_x.append(pixel)\n",
    "                self.tr_y.append(label[i])\n",
    "            else:\n",
    "                self.ts_x.append(pixel)\n",
    "                self.ts_y.append(label[i])\n",
    "                \n",
    "    def getDataset(self):\n",
    "        self.tr_x = np.array(self.tr_x)\n",
    "        self.ts_x = np.array(self.ts_x)\n",
    "        \n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(self.tr_y)\n",
    "        self.tr_y = le.transform(self.tr_y)\n",
    "        \n",
    "        le.fit(self.ts_y)\n",
    "        self.ts_y = le.transform(self.ts_y)\n",
    "        \n",
    "        return [self.tr_x, self.tr_y, self.ts_x, self.ts_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_odn = C100Dataset('../dataset/data/cifar100.csv')\n",
    "[data_odn_tr_x, data_odn_tr_y, data_odn_ts_x, data_odn_ts_y] = dataset_odn.getDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_odn_tr_x = torch.Tensor(data_odn_tr_x)\n",
    "data_odn_ts_x = torch.Tensor(data_odn_ts_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_odn_tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "for i, (tr_y) in enumerate(data_odn_tr_y):\n",
    "    train_dataset.append((data_odn_tr_x[i],int(tr_y)))\n",
    "    \n",
    "test_dataset = []\n",
    "for i, (ts_y) in enumerate(data_odn_ts_y):\n",
    "    test_dataset.append((data_odn_ts_x[i],int(ts_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# device setting\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 30 # number of epochs for train\n",
    "batch_size = 32 # do not change this value 128\n",
    "learning_rate = 0.0001 # do not change this value\n",
    "num_classes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (features): Sequential(\n",
      "    (dense_block_layer_0): Sequential(\n",
      "      (bottle_neck_layer_0): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_1): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_2): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_3): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_4): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_5): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition_layer_0): Transition(\n",
      "      (down_sample): Sequential(\n",
      "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "    )\n",
      "    (dense_block_layer_1): Sequential(\n",
      "      (bottle_neck_layer_0): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_1): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_2): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_3): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_4): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_5): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_6): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_7): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_8): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_9): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_10): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_11): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition_layer_1): Transition(\n",
      "      (down_sample): Sequential(\n",
      "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "    )\n",
      "    (dense_block_layer_2): Sequential(\n",
      "      (bottle_neck_layer_0): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_1): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_2): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_3): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_4): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_5): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_6): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_7): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_8): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_9): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_10): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_11): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_12): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_13): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_14): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_15): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_16): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_17): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_18): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_19): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_20): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_21): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_22): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_23): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition_layer_2): Transition(\n",
      "      (down_sample): Sequential(\n",
      "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "    )\n",
      "    (dense_block3): Sequential(\n",
      "      (bottle_neck_layer_0): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_1): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_2): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_3): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_4): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_5): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_6): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_7): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_8): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_9): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_10): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_11): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_12): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_13): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_14): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottle_neck_layer_15): Bottleneck(\n",
      "        (bottle_neck): Sequential(\n",
      "          (0): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (linear): Linear(in_features=1024, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# train and test\n",
    "# model = VGGNet(num_classes=num_classes).to(device)\n",
    "model = densenet121().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Batch Step: 100/1563, Loss: 4.1868, Training Accuracy of the Current Batch: 9.375%\n",
      "Epoch: 1/100, Batch Step: 200/1563, Loss: 4.1840, Training Accuracy of the Current Batch: 9.375%\n",
      "Epoch: 1/100, Batch Step: 300/1563, Loss: 3.5825, Training Accuracy of the Current Batch: 12.5%\n",
      "Epoch: 1/100, Batch Step: 400/1563, Loss: 3.9900, Training Accuracy of the Current Batch: 3.125%\n",
      "Epoch: 1/100, Batch Step: 500/1563, Loss: 3.7828, Training Accuracy of the Current Batch: 25.0%\n",
      "Epoch: 1/100, Batch Step: 600/1563, Loss: 3.7700, Training Accuracy of the Current Batch: 9.375%\n",
      "Epoch: 1/100, Batch Step: 700/1563, Loss: 3.1395, Training Accuracy of the Current Batch: 28.125%\n",
      "Epoch: 1/100, Batch Step: 800/1563, Loss: 3.2438, Training Accuracy of the Current Batch: 21.875%\n",
      "Epoch: 1/100, Batch Step: 900/1563, Loss: 3.1618, Training Accuracy of the Current Batch: 21.875%\n",
      "Epoch: 1/100, Batch Step: 1000/1563, Loss: 3.1102, Training Accuracy of the Current Batch: 18.75%\n",
      "Epoch: 1/100, Batch Step: 1100/1563, Loss: 3.0795, Training Accuracy of the Current Batch: 15.625%\n",
      "Epoch: 1/100, Batch Step: 1200/1563, Loss: 3.0555, Training Accuracy of the Current Batch: 18.75%\n",
      "Epoch: 1/100, Batch Step: 1300/1563, Loss: 3.1790, Training Accuracy of the Current Batch: 21.875%\n",
      "Epoch: 1/100, Batch Step: 1400/1563, Loss: 2.9522, Training Accuracy of the Current Batch: 18.75%\n",
      "Epoch: 1/100, Batch Step: 1500/1563, Loss: 3.0907, Training Accuracy of the Current Batch: 28.125%\n",
      "Test Accuracy of the 10,000 Test Images: 24.56%\n",
      "\n",
      "Epoch: 2/100, Batch Step: 100/1563, Loss: 3.0037, Training Accuracy of the Current Batch: 15.625%\n",
      "Epoch: 2/100, Batch Step: 200/1563, Loss: 3.3423, Training Accuracy of the Current Batch: 12.5%\n",
      "Epoch: 2/100, Batch Step: 300/1563, Loss: 2.9129, Training Accuracy of the Current Batch: 31.25%\n",
      "Epoch: 2/100, Batch Step: 400/1563, Loss: 3.0680, Training Accuracy of the Current Batch: 28.125%\n",
      "Epoch: 2/100, Batch Step: 500/1563, Loss: 2.4061, Training Accuracy of the Current Batch: 37.5%\n",
      "Epoch: 2/100, Batch Step: 600/1563, Loss: 2.2055, Training Accuracy of the Current Batch: 40.625%\n",
      "Epoch: 2/100, Batch Step: 700/1563, Loss: 2.6220, Training Accuracy of the Current Batch: 31.25%\n",
      "Epoch: 2/100, Batch Step: 800/1563, Loss: 3.0408, Training Accuracy of the Current Batch: 28.125%\n",
      "Epoch: 2/100, Batch Step: 900/1563, Loss: 2.6779, Training Accuracy of the Current Batch: 15.625%\n",
      "Epoch: 2/100, Batch Step: 1000/1563, Loss: 2.8047, Training Accuracy of the Current Batch: 25.0%\n",
      "Epoch: 2/100, Batch Step: 1100/1563, Loss: 2.1994, Training Accuracy of the Current Batch: 40.625%\n",
      "Epoch: 2/100, Batch Step: 1200/1563, Loss: 2.4367, Training Accuracy of the Current Batch: 37.5%\n",
      "Epoch: 2/100, Batch Step: 1300/1563, Loss: 2.4120, Training Accuracy of the Current Batch: 31.25%\n",
      "Epoch: 2/100, Batch Step: 1400/1563, Loss: 2.5101, Training Accuracy of the Current Batch: 25.0%\n",
      "Epoch: 2/100, Batch Step: 1500/1563, Loss: 2.1847, Training Accuracy of the Current Batch: 37.5%\n",
      "Test Accuracy of the 10,000 Test Images: 41.31%\n",
      "\n",
      "Epoch: 3/100, Batch Step: 100/1563, Loss: 2.1589, Training Accuracy of the Current Batch: 43.75%\n",
      "Epoch: 3/100, Batch Step: 200/1563, Loss: 1.7313, Training Accuracy of the Current Batch: 50.0%\n",
      "Epoch: 3/100, Batch Step: 300/1563, Loss: 2.6205, Training Accuracy of the Current Batch: 28.125%\n",
      "Epoch: 3/100, Batch Step: 400/1563, Loss: 1.6796, Training Accuracy of the Current Batch: 50.0%\n",
      "Epoch: 3/100, Batch Step: 500/1563, Loss: 2.1626, Training Accuracy of the Current Batch: 50.0%\n",
      "Epoch: 3/100, Batch Step: 600/1563, Loss: 2.0226, Training Accuracy of the Current Batch: 43.75%\n",
      "Epoch: 3/100, Batch Step: 700/1563, Loss: 1.9166, Training Accuracy of the Current Batch: 53.125%\n",
      "Epoch: 3/100, Batch Step: 800/1563, Loss: 1.7034, Training Accuracy of the Current Batch: 56.25%\n",
      "Epoch: 3/100, Batch Step: 900/1563, Loss: 2.3137, Training Accuracy of the Current Batch: 43.75%\n",
      "Epoch: 3/100, Batch Step: 1000/1563, Loss: 2.0995, Training Accuracy of the Current Batch: 46.875%\n",
      "Epoch: 3/100, Batch Step: 1100/1563, Loss: 2.0137, Training Accuracy of the Current Batch: 34.375%\n",
      "Epoch: 3/100, Batch Step: 1200/1563, Loss: 1.6280, Training Accuracy of the Current Batch: 53.125%\n",
      "Epoch: 3/100, Batch Step: 1300/1563, Loss: 2.1758, Training Accuracy of the Current Batch: 31.25%\n",
      "Epoch: 3/100, Batch Step: 1400/1563, Loss: 1.8351, Training Accuracy of the Current Batch: 50.0%\n",
      "Epoch: 3/100, Batch Step: 1500/1563, Loss: 1.6226, Training Accuracy of the Current Batch: 50.0%\n",
      "Test Accuracy of the 10,000 Test Images: 47.07%\n",
      "\n",
      "Epoch: 4/100, Batch Step: 100/1563, Loss: 2.0254, Training Accuracy of the Current Batch: 37.5%\n",
      "Epoch: 4/100, Batch Step: 200/1563, Loss: 1.5811, Training Accuracy of the Current Batch: 53.125%\n",
      "Epoch: 4/100, Batch Step: 300/1563, Loss: 1.6932, Training Accuracy of the Current Batch: 56.25%\n",
      "Epoch: 4/100, Batch Step: 400/1563, Loss: 1.9560, Training Accuracy of the Current Batch: 56.25%\n",
      "Epoch: 4/100, Batch Step: 500/1563, Loss: 1.6890, Training Accuracy of the Current Batch: 46.875%\n",
      "Epoch: 4/100, Batch Step: 600/1563, Loss: 1.6642, Training Accuracy of the Current Batch: 53.125%\n",
      "Epoch: 4/100, Batch Step: 700/1563, Loss: 1.8399, Training Accuracy of the Current Batch: 62.5%\n",
      "Epoch: 4/100, Batch Step: 800/1563, Loss: 1.6990, Training Accuracy of the Current Batch: 53.125%\n",
      "Epoch: 4/100, Batch Step: 900/1563, Loss: 1.6325, Training Accuracy of the Current Batch: 56.25%\n",
      "Epoch: 4/100, Batch Step: 1000/1563, Loss: 1.8284, Training Accuracy of the Current Batch: 50.0%\n",
      "Epoch: 4/100, Batch Step: 1100/1563, Loss: 1.7799, Training Accuracy of the Current Batch: 46.875%\n",
      "Epoch: 4/100, Batch Step: 1200/1563, Loss: 1.3098, Training Accuracy of the Current Batch: 62.5%\n",
      "Epoch: 4/100, Batch Step: 1300/1563, Loss: 1.5146, Training Accuracy of the Current Batch: 56.25%\n",
      "Epoch: 4/100, Batch Step: 1400/1563, Loss: 1.5750, Training Accuracy of the Current Batch: 50.0%\n",
      "Epoch: 4/100, Batch Step: 1500/1563, Loss: 1.5313, Training Accuracy of the Current Batch: 62.5%\n",
      "Test Accuracy of the 10,000 Test Images: 53.23%\n",
      "\n",
      "Epoch: 5/100, Batch Step: 100/1563, Loss: 1.4490, Training Accuracy of the Current Batch: 62.5%\n",
      "Epoch: 5/100, Batch Step: 200/1563, Loss: 1.5310, Training Accuracy of the Current Batch: 62.5%\n",
      "Epoch: 5/100, Batch Step: 300/1563, Loss: 1.0930, Training Accuracy of the Current Batch: 62.5%\n",
      "Epoch: 5/100, Batch Step: 400/1563, Loss: 1.1487, Training Accuracy of the Current Batch: 71.875%\n",
      "Epoch: 5/100, Batch Step: 500/1563, Loss: 1.6177, Training Accuracy of the Current Batch: 56.25%\n",
      "Epoch: 5/100, Batch Step: 600/1563, Loss: 1.1413, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 5/100, Batch Step: 700/1563, Loss: 1.8515, Training Accuracy of the Current Batch: 31.25%\n",
      "Epoch: 5/100, Batch Step: 800/1563, Loss: 1.4779, Training Accuracy of the Current Batch: 56.25%\n",
      "Epoch: 5/100, Batch Step: 900/1563, Loss: 1.1505, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 5/100, Batch Step: 1000/1563, Loss: 1.6165, Training Accuracy of the Current Batch: 50.0%\n",
      "Epoch: 5/100, Batch Step: 1100/1563, Loss: 1.3549, Training Accuracy of the Current Batch: 50.0%\n",
      "Epoch: 5/100, Batch Step: 1200/1563, Loss: 1.7907, Training Accuracy of the Current Batch: 46.875%\n",
      "Epoch: 5/100, Batch Step: 1300/1563, Loss: 1.7428, Training Accuracy of the Current Batch: 50.0%\n",
      "Epoch: 5/100, Batch Step: 1400/1563, Loss: 1.7956, Training Accuracy of the Current Batch: 50.0%\n",
      "Epoch: 5/100, Batch Step: 1500/1563, Loss: 0.8736, Training Accuracy of the Current Batch: 71.875%\n",
      "Test Accuracy of the 10,000 Test Images: 56.06%\n",
      "\n",
      "Epoch: 6/100, Batch Step: 100/1563, Loss: 1.5753, Training Accuracy of the Current Batch: 56.25%\n",
      "Epoch: 6/100, Batch Step: 200/1563, Loss: 1.2919, Training Accuracy of the Current Batch: 68.75%\n",
      "Epoch: 6/100, Batch Step: 300/1563, Loss: 0.7869, Training Accuracy of the Current Batch: 71.875%\n",
      "Epoch: 6/100, Batch Step: 400/1563, Loss: 0.9128, Training Accuracy of the Current Batch: 68.75%\n",
      "Epoch: 6/100, Batch Step: 500/1563, Loss: 0.7350, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 6/100, Batch Step: 600/1563, Loss: 1.3250, Training Accuracy of the Current Batch: 53.125%\n",
      "Epoch: 6/100, Batch Step: 700/1563, Loss: 1.2527, Training Accuracy of the Current Batch: 56.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100, Batch Step: 800/1563, Loss: 1.1144, Training Accuracy of the Current Batch: 65.625%\n",
      "Epoch: 6/100, Batch Step: 900/1563, Loss: 1.1449, Training Accuracy of the Current Batch: 59.375%\n",
      "Epoch: 6/100, Batch Step: 1000/1563, Loss: 1.0940, Training Accuracy of the Current Batch: 56.25%\n",
      "Epoch: 6/100, Batch Step: 1100/1563, Loss: 0.9245, Training Accuracy of the Current Batch: 62.5%\n",
      "Epoch: 6/100, Batch Step: 1200/1563, Loss: 1.3170, Training Accuracy of the Current Batch: 68.75%\n",
      "Epoch: 6/100, Batch Step: 1300/1563, Loss: 1.2541, Training Accuracy of the Current Batch: 56.25%\n",
      "Epoch: 6/100, Batch Step: 1400/1563, Loss: 0.9682, Training Accuracy of the Current Batch: 65.625%\n",
      "Epoch: 6/100, Batch Step: 1500/1563, Loss: 1.4599, Training Accuracy of the Current Batch: 59.375%\n",
      "Test Accuracy of the 10,000 Test Images: 57.57%\n",
      "\n",
      "Epoch: 7/100, Batch Step: 100/1563, Loss: 1.0495, Training Accuracy of the Current Batch: 65.625%\n",
      "Epoch: 7/100, Batch Step: 200/1563, Loss: 0.5841, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 7/100, Batch Step: 300/1563, Loss: 1.2628, Training Accuracy of the Current Batch: 59.375%\n",
      "Epoch: 7/100, Batch Step: 400/1563, Loss: 0.9190, Training Accuracy of the Current Batch: 71.875%\n",
      "Epoch: 7/100, Batch Step: 500/1563, Loss: 1.1466, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 7/100, Batch Step: 600/1563, Loss: 1.1743, Training Accuracy of the Current Batch: 68.75%\n",
      "Epoch: 7/100, Batch Step: 700/1563, Loss: 2.0362, Training Accuracy of the Current Batch: 40.625%\n",
      "Epoch: 7/100, Batch Step: 800/1563, Loss: 0.8113, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 7/100, Batch Step: 900/1563, Loss: 0.5970, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 7/100, Batch Step: 1000/1563, Loss: 1.3126, Training Accuracy of the Current Batch: 65.625%\n",
      "Epoch: 7/100, Batch Step: 1100/1563, Loss: 0.7326, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 7/100, Batch Step: 1200/1563, Loss: 0.7373, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 7/100, Batch Step: 1300/1563, Loss: 1.1924, Training Accuracy of the Current Batch: 56.25%\n",
      "Epoch: 7/100, Batch Step: 1400/1563, Loss: 1.4586, Training Accuracy of the Current Batch: 62.5%\n",
      "Epoch: 7/100, Batch Step: 1500/1563, Loss: 1.0480, Training Accuracy of the Current Batch: 75.0%\n",
      "Test Accuracy of the 10,000 Test Images: 59.58%\n",
      "\n",
      "Epoch: 8/100, Batch Step: 100/1563, Loss: 0.8342, Training Accuracy of the Current Batch: 68.75%\n",
      "Epoch: 8/100, Batch Step: 200/1563, Loss: 0.5809, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 8/100, Batch Step: 300/1563, Loss: 0.9982, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 8/100, Batch Step: 400/1563, Loss: 1.0089, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 8/100, Batch Step: 500/1563, Loss: 0.8686, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 8/100, Batch Step: 600/1563, Loss: 0.8157, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 8/100, Batch Step: 700/1563, Loss: 1.3988, Training Accuracy of the Current Batch: 65.625%\n",
      "Epoch: 8/100, Batch Step: 800/1563, Loss: 1.1833, Training Accuracy of the Current Batch: 59.375%\n",
      "Epoch: 8/100, Batch Step: 900/1563, Loss: 0.7200, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 8/100, Batch Step: 1000/1563, Loss: 0.8609, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 8/100, Batch Step: 1100/1563, Loss: 0.9857, Training Accuracy of the Current Batch: 62.5%\n",
      "Epoch: 8/100, Batch Step: 1200/1563, Loss: 1.8064, Training Accuracy of the Current Batch: 43.75%\n",
      "Epoch: 8/100, Batch Step: 1300/1563, Loss: 0.4544, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 8/100, Batch Step: 1400/1563, Loss: 0.9094, Training Accuracy of the Current Batch: 71.875%\n",
      "Epoch: 8/100, Batch Step: 1500/1563, Loss: 0.9933, Training Accuracy of the Current Batch: 68.75%\n",
      "Test Accuracy of the 10,000 Test Images: 61.18%\n",
      "\n",
      "Epoch: 9/100, Batch Step: 100/1563, Loss: 0.3962, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 9/100, Batch Step: 200/1563, Loss: 0.7192, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 9/100, Batch Step: 300/1563, Loss: 0.6367, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 9/100, Batch Step: 400/1563, Loss: 0.6840, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 9/100, Batch Step: 500/1563, Loss: 0.7301, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 9/100, Batch Step: 600/1563, Loss: 0.9200, Training Accuracy of the Current Batch: 59.375%\n",
      "Epoch: 9/100, Batch Step: 700/1563, Loss: 0.8351, Training Accuracy of the Current Batch: 68.75%\n",
      "Epoch: 9/100, Batch Step: 800/1563, Loss: 0.6545, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 9/100, Batch Step: 900/1563, Loss: 0.5366, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 9/100, Batch Step: 1000/1563, Loss: 0.7289, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 9/100, Batch Step: 1100/1563, Loss: 0.4517, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 9/100, Batch Step: 1200/1563, Loss: 0.5191, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 9/100, Batch Step: 1300/1563, Loss: 1.0364, Training Accuracy of the Current Batch: 65.625%\n",
      "Epoch: 9/100, Batch Step: 1400/1563, Loss: 0.8301, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 9/100, Batch Step: 1500/1563, Loss: 0.9190, Training Accuracy of the Current Batch: 78.125%\n",
      "Test Accuracy of the 10,000 Test Images: 61.33%\n",
      "\n",
      "Epoch: 10/100, Batch Step: 100/1563, Loss: 0.4774, Training Accuracy of the Current Batch: 81.25%\n",
      "Epoch: 10/100, Batch Step: 200/1563, Loss: 0.7939, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 10/100, Batch Step: 300/1563, Loss: 0.4032, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 10/100, Batch Step: 400/1563, Loss: 0.4300, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 10/100, Batch Step: 500/1563, Loss: 0.6699, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 10/100, Batch Step: 600/1563, Loss: 0.5882, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 10/100, Batch Step: 700/1563, Loss: 0.7225, Training Accuracy of the Current Batch: 68.75%\n",
      "Epoch: 10/100, Batch Step: 800/1563, Loss: 0.4438, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 10/100, Batch Step: 900/1563, Loss: 0.5077, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 10/100, Batch Step: 1000/1563, Loss: 0.7973, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 10/100, Batch Step: 1100/1563, Loss: 0.5658, Training Accuracy of the Current Batch: 81.25%\n",
      "Epoch: 10/100, Batch Step: 1200/1563, Loss: 0.6874, Training Accuracy of the Current Batch: 81.25%\n",
      "Epoch: 10/100, Batch Step: 1300/1563, Loss: 0.6994, Training Accuracy of the Current Batch: 81.25%\n",
      "Epoch: 10/100, Batch Step: 1400/1563, Loss: 0.6149, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 10/100, Batch Step: 1500/1563, Loss: 0.3786, Training Accuracy of the Current Batch: 93.75%\n",
      "Test Accuracy of the 10,000 Test Images: 61.23%\n",
      "\n",
      "Epoch: 11/100, Batch Step: 100/1563, Loss: 0.3037, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 11/100, Batch Step: 200/1563, Loss: 0.5871, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 11/100, Batch Step: 300/1563, Loss: 0.2992, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 11/100, Batch Step: 400/1563, Loss: 0.2646, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 11/100, Batch Step: 500/1563, Loss: 0.7580, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 11/100, Batch Step: 600/1563, Loss: 0.3178, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 11/100, Batch Step: 700/1563, Loss: 0.3181, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 11/100, Batch Step: 800/1563, Loss: 0.4301, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 11/100, Batch Step: 900/1563, Loss: 0.4318, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 11/100, Batch Step: 1000/1563, Loss: 0.4449, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 11/100, Batch Step: 1100/1563, Loss: 0.2285, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 11/100, Batch Step: 1200/1563, Loss: 0.3904, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 11/100, Batch Step: 1300/1563, Loss: 0.5139, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 11/100, Batch Step: 1400/1563, Loss: 0.7425, Training Accuracy of the Current Batch: 71.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100, Batch Step: 1500/1563, Loss: 0.4535, Training Accuracy of the Current Batch: 84.375%\n",
      "Test Accuracy of the 10,000 Test Images: 62.38%\n",
      "\n",
      "Epoch: 12/100, Batch Step: 100/1563, Loss: 0.3444, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 12/100, Batch Step: 200/1563, Loss: 0.2057, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 12/100, Batch Step: 300/1563, Loss: 0.4687, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 12/100, Batch Step: 400/1563, Loss: 0.3380, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 12/100, Batch Step: 500/1563, Loss: 0.6165, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 12/100, Batch Step: 600/1563, Loss: 0.4621, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 12/100, Batch Step: 700/1563, Loss: 0.5611, Training Accuracy of the Current Batch: 81.25%\n",
      "Epoch: 12/100, Batch Step: 800/1563, Loss: 0.7257, Training Accuracy of the Current Batch: 75.0%\n",
      "Epoch: 12/100, Batch Step: 900/1563, Loss: 0.4582, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 12/100, Batch Step: 1000/1563, Loss: 0.5237, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 12/100, Batch Step: 1100/1563, Loss: 0.5416, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 12/100, Batch Step: 1200/1563, Loss: 0.6888, Training Accuracy of the Current Batch: 81.25%\n",
      "Epoch: 12/100, Batch Step: 1300/1563, Loss: 0.2728, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 12/100, Batch Step: 1400/1563, Loss: 0.2884, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 12/100, Batch Step: 1500/1563, Loss: 0.7216, Training Accuracy of the Current Batch: 78.125%\n",
      "Test Accuracy of the 10,000 Test Images: 61.39%\n",
      "\n",
      "Epoch: 13/100, Batch Step: 100/1563, Loss: 0.3721, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 13/100, Batch Step: 200/1563, Loss: 0.1821, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 13/100, Batch Step: 300/1563, Loss: 0.3705, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 13/100, Batch Step: 400/1563, Loss: 0.4814, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 13/100, Batch Step: 500/1563, Loss: 0.2790, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 13/100, Batch Step: 600/1563, Loss: 0.4727, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 13/100, Batch Step: 700/1563, Loss: 0.3466, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 13/100, Batch Step: 800/1563, Loss: 0.5927, Training Accuracy of the Current Batch: 78.125%\n",
      "Epoch: 13/100, Batch Step: 900/1563, Loss: 0.4530, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 13/100, Batch Step: 1000/1563, Loss: 0.3766, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 13/100, Batch Step: 1100/1563, Loss: 0.2637, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 13/100, Batch Step: 1200/1563, Loss: 0.3854, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 13/100, Batch Step: 1300/1563, Loss: 0.3905, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 13/100, Batch Step: 1400/1563, Loss: 0.3055, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 13/100, Batch Step: 1500/1563, Loss: 0.4076, Training Accuracy of the Current Batch: 90.625%\n",
      "Test Accuracy of the 10,000 Test Images: 62.4%\n",
      "\n",
      "Epoch: 14/100, Batch Step: 100/1563, Loss: 0.1399, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 14/100, Batch Step: 200/1563, Loss: 0.3297, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 14/100, Batch Step: 300/1563, Loss: 0.1060, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 14/100, Batch Step: 400/1563, Loss: 0.4056, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 14/100, Batch Step: 500/1563, Loss: 0.4759, Training Accuracy of the Current Batch: 81.25%\n",
      "Epoch: 14/100, Batch Step: 600/1563, Loss: 0.3321, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 14/100, Batch Step: 700/1563, Loss: 0.4773, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 14/100, Batch Step: 800/1563, Loss: 0.2889, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 14/100, Batch Step: 900/1563, Loss: 0.3486, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 14/100, Batch Step: 1000/1563, Loss: 0.2469, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 14/100, Batch Step: 1100/1563, Loss: 0.4526, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 14/100, Batch Step: 1200/1563, Loss: 0.3949, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 14/100, Batch Step: 1300/1563, Loss: 0.5024, Training Accuracy of the Current Batch: 81.25%\n",
      "Epoch: 14/100, Batch Step: 1400/1563, Loss: 0.4636, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 14/100, Batch Step: 1500/1563, Loss: 0.2610, Training Accuracy of the Current Batch: 96.875%\n",
      "Test Accuracy of the 10,000 Test Images: 60.37%\n",
      "\n",
      "Epoch: 15/100, Batch Step: 100/1563, Loss: 0.1968, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 15/100, Batch Step: 200/1563, Loss: 0.3343, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 15/100, Batch Step: 300/1563, Loss: 0.1516, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 15/100, Batch Step: 400/1563, Loss: 0.3802, Training Accuracy of the Current Batch: 81.25%\n",
      "Epoch: 15/100, Batch Step: 500/1563, Loss: 0.1373, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 15/100, Batch Step: 600/1563, Loss: 0.2051, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 15/100, Batch Step: 700/1563, Loss: 0.2842, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 15/100, Batch Step: 800/1563, Loss: 0.2603, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 15/100, Batch Step: 900/1563, Loss: 0.2693, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 15/100, Batch Step: 1000/1563, Loss: 0.1637, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 15/100, Batch Step: 1100/1563, Loss: 0.2315, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 15/100, Batch Step: 1200/1563, Loss: 0.1741, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 15/100, Batch Step: 1300/1563, Loss: 0.3040, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 15/100, Batch Step: 1400/1563, Loss: 0.3778, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 15/100, Batch Step: 1500/1563, Loss: 0.1114, Training Accuracy of the Current Batch: 96.875%\n",
      "Test Accuracy of the 10,000 Test Images: 61.72%\n",
      "\n",
      "Epoch: 16/100, Batch Step: 100/1563, Loss: 0.2782, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 16/100, Batch Step: 200/1563, Loss: 0.2964, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 16/100, Batch Step: 300/1563, Loss: 0.2342, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 16/100, Batch Step: 400/1563, Loss: 0.3170, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 16/100, Batch Step: 500/1563, Loss: 0.0935, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 16/100, Batch Step: 600/1563, Loss: 0.3793, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 16/100, Batch Step: 700/1563, Loss: 0.3569, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 16/100, Batch Step: 800/1563, Loss: 0.2086, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 16/100, Batch Step: 900/1563, Loss: 0.1572, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 16/100, Batch Step: 1000/1563, Loss: 0.1794, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 16/100, Batch Step: 1100/1563, Loss: 0.3133, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 16/100, Batch Step: 1200/1563, Loss: 0.3589, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 16/100, Batch Step: 1300/1563, Loss: 0.4202, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 16/100, Batch Step: 1400/1563, Loss: 0.1467, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 16/100, Batch Step: 1500/1563, Loss: 0.3540, Training Accuracy of the Current Batch: 90.625%\n",
      "Test Accuracy of the 10,000 Test Images: 61.13%\n",
      "\n",
      "Epoch: 17/100, Batch Step: 100/1563, Loss: 0.1798, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 17/100, Batch Step: 200/1563, Loss: 0.1687, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 17/100, Batch Step: 300/1563, Loss: 0.1051, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 17/100, Batch Step: 400/1563, Loss: 0.0800, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 17/100, Batch Step: 500/1563, Loss: 0.1630, Training Accuracy of the Current Batch: 93.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100, Batch Step: 600/1563, Loss: 0.2100, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 17/100, Batch Step: 700/1563, Loss: 0.3748, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 17/100, Batch Step: 800/1563, Loss: 0.1949, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 17/100, Batch Step: 900/1563, Loss: 0.1879, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 17/100, Batch Step: 1000/1563, Loss: 0.1996, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 17/100, Batch Step: 1100/1563, Loss: 0.2489, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 17/100, Batch Step: 1200/1563, Loss: 0.3853, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 17/100, Batch Step: 1300/1563, Loss: 0.3987, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 17/100, Batch Step: 1400/1563, Loss: 0.1623, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 17/100, Batch Step: 1500/1563, Loss: 0.3181, Training Accuracy of the Current Batch: 87.5%\n",
      "Test Accuracy of the 10,000 Test Images: 62.66%\n",
      "\n",
      "Epoch: 18/100, Batch Step: 100/1563, Loss: 0.0602, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 18/100, Batch Step: 200/1563, Loss: 0.0872, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 18/100, Batch Step: 300/1563, Loss: 0.1562, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 18/100, Batch Step: 400/1563, Loss: 0.3016, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 18/100, Batch Step: 500/1563, Loss: 0.1450, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 18/100, Batch Step: 600/1563, Loss: 0.0893, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 18/100, Batch Step: 700/1563, Loss: 0.0869, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 18/100, Batch Step: 800/1563, Loss: 0.0956, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 18/100, Batch Step: 900/1563, Loss: 0.1670, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 18/100, Batch Step: 1000/1563, Loss: 0.3808, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 18/100, Batch Step: 1100/1563, Loss: 0.2106, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 18/100, Batch Step: 1200/1563, Loss: 0.1235, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 18/100, Batch Step: 1300/1563, Loss: 0.1838, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 18/100, Batch Step: 1400/1563, Loss: 0.2206, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 18/100, Batch Step: 1500/1563, Loss: 0.2421, Training Accuracy of the Current Batch: 93.75%\n",
      "Test Accuracy of the 10,000 Test Images: 62.68%\n",
      "\n",
      "Epoch: 19/100, Batch Step: 100/1563, Loss: 0.1514, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 19/100, Batch Step: 200/1563, Loss: 0.0896, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 19/100, Batch Step: 300/1563, Loss: 0.1789, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 19/100, Batch Step: 400/1563, Loss: 0.0913, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 19/100, Batch Step: 500/1563, Loss: 0.1496, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 19/100, Batch Step: 600/1563, Loss: 0.5310, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 19/100, Batch Step: 700/1563, Loss: 0.2484, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 19/100, Batch Step: 800/1563, Loss: 0.1226, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 19/100, Batch Step: 900/1563, Loss: 0.0928, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 19/100, Batch Step: 1000/1563, Loss: 0.1284, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 19/100, Batch Step: 1100/1563, Loss: 0.2704, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 19/100, Batch Step: 1200/1563, Loss: 0.3116, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 19/100, Batch Step: 1300/1563, Loss: 0.2266, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 19/100, Batch Step: 1400/1563, Loss: 0.3437, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 19/100, Batch Step: 1500/1563, Loss: 0.1893, Training Accuracy of the Current Batch: 93.75%\n",
      "Test Accuracy of the 10,000 Test Images: 61.94%\n",
      "\n",
      "Epoch: 20/100, Batch Step: 100/1563, Loss: 0.2219, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 20/100, Batch Step: 200/1563, Loss: 0.0491, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 20/100, Batch Step: 300/1563, Loss: 0.1189, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 20/100, Batch Step: 400/1563, Loss: 0.1098, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 20/100, Batch Step: 500/1563, Loss: 0.0994, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 20/100, Batch Step: 600/1563, Loss: 0.0352, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 20/100, Batch Step: 700/1563, Loss: 0.1041, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 20/100, Batch Step: 800/1563, Loss: 0.0448, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 20/100, Batch Step: 900/1563, Loss: 0.1360, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 20/100, Batch Step: 1000/1563, Loss: 0.2005, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 20/100, Batch Step: 1100/1563, Loss: 0.0326, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 20/100, Batch Step: 1200/1563, Loss: 0.1691, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 20/100, Batch Step: 1300/1563, Loss: 0.2667, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 20/100, Batch Step: 1400/1563, Loss: 0.1174, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 20/100, Batch Step: 1500/1563, Loss: 0.1803, Training Accuracy of the Current Batch: 90.625%\n",
      "Test Accuracy of the 10,000 Test Images: 62.0%\n",
      "\n",
      "Epoch: 21/100, Batch Step: 100/1563, Loss: 0.0902, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 21/100, Batch Step: 200/1563, Loss: 0.0962, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 21/100, Batch Step: 300/1563, Loss: 0.0439, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 21/100, Batch Step: 400/1563, Loss: 0.1515, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 21/100, Batch Step: 500/1563, Loss: 0.3734, Training Accuracy of the Current Batch: 81.25%\n",
      "Epoch: 21/100, Batch Step: 600/1563, Loss: 0.0367, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 21/100, Batch Step: 700/1563, Loss: 0.1348, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 21/100, Batch Step: 800/1563, Loss: 0.1146, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 21/100, Batch Step: 900/1563, Loss: 0.0427, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 21/100, Batch Step: 1000/1563, Loss: 0.2899, Training Accuracy of the Current Batch: 87.5%\n",
      "Epoch: 21/100, Batch Step: 1100/1563, Loss: 0.1681, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 21/100, Batch Step: 1200/1563, Loss: 0.0725, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 21/100, Batch Step: 1300/1563, Loss: 0.2851, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 21/100, Batch Step: 1400/1563, Loss: 0.1689, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 21/100, Batch Step: 1500/1563, Loss: 0.2393, Training Accuracy of the Current Batch: 87.5%\n",
      "Test Accuracy of the 10,000 Test Images: 62.09%\n",
      "\n",
      "Epoch: 22/100, Batch Step: 100/1563, Loss: 0.0328, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 22/100, Batch Step: 200/1563, Loss: 0.0386, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 22/100, Batch Step: 300/1563, Loss: 0.0741, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 22/100, Batch Step: 400/1563, Loss: 0.0421, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 22/100, Batch Step: 500/1563, Loss: 0.0537, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 22/100, Batch Step: 600/1563, Loss: 0.1259, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 22/100, Batch Step: 700/1563, Loss: 0.0893, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 22/100, Batch Step: 800/1563, Loss: 0.1501, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 22/100, Batch Step: 900/1563, Loss: 0.0916, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 22/100, Batch Step: 1000/1563, Loss: 0.0459, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 22/100, Batch Step: 1100/1563, Loss: 0.2777, Training Accuracy of the Current Batch: 93.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100, Batch Step: 1200/1563, Loss: 0.0767, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 22/100, Batch Step: 1300/1563, Loss: 0.2930, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 22/100, Batch Step: 1400/1563, Loss: 0.0716, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 22/100, Batch Step: 1500/1563, Loss: 0.1465, Training Accuracy of the Current Batch: 96.875%\n",
      "Test Accuracy of the 10,000 Test Images: 62.73%\n",
      "\n",
      "Epoch: 23/100, Batch Step: 100/1563, Loss: 0.1368, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 23/100, Batch Step: 200/1563, Loss: 0.1944, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 23/100, Batch Step: 300/1563, Loss: 0.0367, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 23/100, Batch Step: 400/1563, Loss: 0.0529, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 23/100, Batch Step: 500/1563, Loss: 0.0324, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 23/100, Batch Step: 600/1563, Loss: 0.1078, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 23/100, Batch Step: 700/1563, Loss: 0.2061, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 23/100, Batch Step: 800/1563, Loss: 0.0785, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 23/100, Batch Step: 900/1563, Loss: 0.3349, Training Accuracy of the Current Batch: 81.25%\n",
      "Epoch: 23/100, Batch Step: 1000/1563, Loss: 0.0153, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 23/100, Batch Step: 1100/1563, Loss: 0.0369, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 23/100, Batch Step: 1200/1563, Loss: 0.1102, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 23/100, Batch Step: 1300/1563, Loss: 0.1117, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 23/100, Batch Step: 1400/1563, Loss: 0.1016, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 23/100, Batch Step: 1500/1563, Loss: 0.5029, Training Accuracy of the Current Batch: 84.375%\n",
      "Test Accuracy of the 10,000 Test Images: 61.94%\n",
      "\n",
      "Epoch: 24/100, Batch Step: 100/1563, Loss: 0.0329, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 24/100, Batch Step: 200/1563, Loss: 0.0288, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 24/100, Batch Step: 300/1563, Loss: 0.1149, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 24/100, Batch Step: 400/1563, Loss: 0.0247, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 24/100, Batch Step: 500/1563, Loss: 0.0272, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 24/100, Batch Step: 600/1563, Loss: 0.0962, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 24/100, Batch Step: 700/1563, Loss: 0.0320, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 24/100, Batch Step: 800/1563, Loss: 0.1201, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 24/100, Batch Step: 900/1563, Loss: 0.0972, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 24/100, Batch Step: 1000/1563, Loss: 0.1420, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 24/100, Batch Step: 1100/1563, Loss: 0.2034, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 24/100, Batch Step: 1200/1563, Loss: 0.1697, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 24/100, Batch Step: 1300/1563, Loss: 0.1255, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 24/100, Batch Step: 1400/1563, Loss: 0.2273, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 24/100, Batch Step: 1500/1563, Loss: 0.2232, Training Accuracy of the Current Batch: 90.625%\n",
      "Test Accuracy of the 10,000 Test Images: 63.01%\n",
      "\n",
      "Epoch: 25/100, Batch Step: 100/1563, Loss: 0.0932, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 25/100, Batch Step: 200/1563, Loss: 0.0532, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 25/100, Batch Step: 300/1563, Loss: 0.0706, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 25/100, Batch Step: 400/1563, Loss: 0.0733, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 25/100, Batch Step: 500/1563, Loss: 0.1079, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 25/100, Batch Step: 600/1563, Loss: 0.0764, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 25/100, Batch Step: 700/1563, Loss: 0.1503, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 25/100, Batch Step: 800/1563, Loss: 0.1704, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 25/100, Batch Step: 900/1563, Loss: 0.0687, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 25/100, Batch Step: 1000/1563, Loss: 0.1045, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 25/100, Batch Step: 1100/1563, Loss: 0.1250, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 25/100, Batch Step: 1200/1563, Loss: 0.1443, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 25/100, Batch Step: 1300/1563, Loss: 0.1407, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 25/100, Batch Step: 1400/1563, Loss: 0.1025, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 25/100, Batch Step: 1500/1563, Loss: 0.0771, Training Accuracy of the Current Batch: 96.875%\n",
      "Test Accuracy of the 10,000 Test Images: 63.21%\n",
      "\n",
      "Epoch: 26/100, Batch Step: 100/1563, Loss: 0.0089, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 26/100, Batch Step: 200/1563, Loss: 0.0533, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 26/100, Batch Step: 300/1563, Loss: 0.0610, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 26/100, Batch Step: 400/1563, Loss: 0.0289, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 26/100, Batch Step: 500/1563, Loss: 0.0805, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 26/100, Batch Step: 600/1563, Loss: 0.0922, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 26/100, Batch Step: 700/1563, Loss: 0.2654, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 26/100, Batch Step: 800/1563, Loss: 0.1414, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 26/100, Batch Step: 900/1563, Loss: 0.0372, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 26/100, Batch Step: 1000/1563, Loss: 0.0449, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 26/100, Batch Step: 1100/1563, Loss: 0.0475, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 26/100, Batch Step: 1200/1563, Loss: 0.1575, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 26/100, Batch Step: 1300/1563, Loss: 0.2579, Training Accuracy of the Current Batch: 84.375%\n",
      "Epoch: 26/100, Batch Step: 1400/1563, Loss: 0.0725, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 26/100, Batch Step: 1500/1563, Loss: 0.1887, Training Accuracy of the Current Batch: 93.75%\n",
      "Test Accuracy of the 10,000 Test Images: 63.49%\n",
      "\n",
      "Epoch: 27/100, Batch Step: 100/1563, Loss: 0.0952, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 27/100, Batch Step: 200/1563, Loss: 0.0248, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 27/100, Batch Step: 300/1563, Loss: 0.1180, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 27/100, Batch Step: 400/1563, Loss: 0.1157, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 27/100, Batch Step: 500/1563, Loss: 0.0463, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 27/100, Batch Step: 600/1563, Loss: 0.1163, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 27/100, Batch Step: 700/1563, Loss: 0.0391, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 27/100, Batch Step: 800/1563, Loss: 0.0956, Training Accuracy of the Current Batch: 93.75%\n",
      "Epoch: 27/100, Batch Step: 900/1563, Loss: 0.0190, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 27/100, Batch Step: 1000/1563, Loss: 0.0672, Training Accuracy of the Current Batch: 96.875%\n",
      "Epoch: 27/100, Batch Step: 1100/1563, Loss: 0.0850, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 27/100, Batch Step: 1200/1563, Loss: 0.0237, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 27/100, Batch Step: 1300/1563, Loss: 0.2861, Training Accuracy of the Current Batch: 90.625%\n",
      "Epoch: 27/100, Batch Step: 1400/1563, Loss: 0.0384, Training Accuracy of the Current Batch: 100.0%\n",
      "Epoch: 27/100, Batch Step: 1500/1563, Loss: 0.1746, Training Accuracy of the Current Batch: 93.75%\n",
      "Test Accuracy of the 10,000 Test Images: 62.69%\n",
      "\n",
      "Epoch: 28/100, Batch Step: 100/1563, Loss: 0.0718, Training Accuracy of the Current Batch: 100.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-2e13ca0a37e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neuroevo\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    190\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m                         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_arr = []\n",
    "train_acc_arr = []\n",
    "\n",
    "val_loss_arr = []\n",
    "val_acc_arr = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        \n",
    "        losses.update(loss.item(), labels.size(0))\n",
    "        acces.update(100 * correct / batch_size, labels.size(0))\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch: {}/{}, Batch Step: {}/{}, Loss: {:.4f}, Training Accuracy of the Current Batch: {}%'.\n",
    "                  format(epoch + 1, num_epochs, i + 1, train_loader.__len__(), loss.item(), 100 * correct / batch_size))\n",
    "            \n",
    "    train_loss_arr.append(losses.avg)\n",
    "    train_acc_arr.append(acces.avg)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        total, correct  = 0, 0\n",
    "\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            losses.update(loss.item(), labels.size(0))\n",
    "\n",
    "        val_loss_arr.append(losses.avg)\n",
    "        val_acc_arr.append(100 * correct / total)\n",
    "\n",
    "        print('Test Accuracy of the 10,000 Test Images: {}%\\n'.format(100 * correct / total))\n",
    "    \n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"number of parameters:\", pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw the graph\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training Loss\")\n",
    "plt.plot(train_loss_arr,label=\"train\")\n",
    "plt.plot(val_loss_arr,label=\"test\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Training Accuracy\")\n",
    "plt.plot(train_acc_arr,label=\"train\")\n",
    "plt.plot(val_acc_arr,label=\"test\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
