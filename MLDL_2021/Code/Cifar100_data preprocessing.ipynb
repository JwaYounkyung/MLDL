{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import PIL.Image as pilimg\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from models.densenet import densenet121\n",
    "from models.vgg import VGGNet\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C100Dataset:\n",
    "    \"\"\"\n",
    "    X is a feature vector\n",
    "    Y is the predictor variable\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        ## read the csv for dataset (cifar100.csv, cifar100_lt.csv or cifar100_nl.csv), \n",
    "        # \n",
    "        # Format:\n",
    "        #   image file path,classname\n",
    "        \n",
    "        ### TODO: Read the csv file and make the training and testing set\n",
    "        ## YOUR CODE HERE\n",
    "        self.filename=filename\n",
    "        f=open(filename)\n",
    "        rdr=csv.reader(f)\n",
    "        path=[]\n",
    "        label=[]\n",
    "        \n",
    "        for line in rdr:\n",
    "            rpath=line[0].replace('cifar100','../dataset')\n",
    "            path.append(rpath)\n",
    "            label.append(line[1])\n",
    "        f.close()\n",
    "\n",
    "        self.tr_x = []\n",
    "        self.tr_y = []\n",
    "        self.ts_x = []\n",
    "        self.ts_y = []\n",
    "\n",
    "\n",
    "        for i in range(len(label)):\n",
    "            img = pilimg.open(path[i])#path 읽어와서 이미지 열기\n",
    "            pixel = np.array(img)\n",
    "            pixel = np.transpose(pixel, (2, 1, 0))\n",
    "            cat=path[i].split('/')\n",
    "            if cat[3]=='train':\n",
    "                self.tr_x.append(pixel)\n",
    "                self.tr_y.append(label[i])\n",
    "            else:\n",
    "                self.ts_x.append(pixel)\n",
    "                self.ts_y.append(label[i])\n",
    "                \n",
    "    def getDataset(self):\n",
    "        self.tr_x = np.array(self.tr_x)\n",
    "        self.ts_x = np.array(self.ts_x)\n",
    "        \n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(self.tr_y)\n",
    "        self.tr_y = le.transform(self.tr_y)\n",
    "        \n",
    "        le.fit(self.ts_y)\n",
    "        self.ts_y = le.transform(self.ts_y)\n",
    "        \n",
    "        return [self.tr_x, self.tr_y, self.ts_x, self.ts_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_odn = C100Dataset('../dataset/data/cifar100.csv')\n",
    "[data_odn_tr_x, data_odn_tr_y, data_odn_ts_x, data_odn_ts_y] = dataset_odn.getDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_odn_tr_x = torch.Tensor(data_odn_tr_x)\n",
    "data_odn_ts_x = torch.Tensor(data_odn_ts_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_odn_tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "for i, (tr_y) in enumerate(data_odn_tr_y):\n",
    "    train_dataset.append((data_odn_tr_x[i],int(tr_y)))\n",
    "    \n",
    "test_dataset = []\n",
    "for i, (ts_y) in enumerate(data_odn_ts_y):\n",
    "    test_dataset.append((data_odn_ts_x[i],int(ts_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# device setting\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 30 # number of epochs for train\n",
    "batch_size = 32 # do not change this value 128\n",
    "learning_rate = 0.0001 # do not change this value\n",
    "num_classes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
